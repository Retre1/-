#!/usr/bin/env python3
"""
üéì –ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è ForexBot AI
–ü–æ–¥—Ä–æ–±–Ω–æ–µ —Ä—É–∫–æ–≤–æ–¥—Å—Ç–≤–æ –ø–æ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import json
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import pickle
import joblib
from sklearn.model_selection import train_test_split, TimeSeriesSplit
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns
from dataclasses import dataclass
import warnings
warnings.filterwarnings('ignore')

# –ò–º–ø–æ—Ä—Ç –Ω–∞—à–∏—Ö –º–æ–¥—É–ª–µ–π
from advanced_ai_models import AdvancedFeatureEngineer, AdvancedEnsembleModel
from advanced_backtesting import AdvancedBacktester, PerformanceAnalyzer

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('training.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

@dataclass
class TrainingConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    symbol: str
    timeframe: str
    lookback_periods: List[int] = None
    test_size: float = 0.2
    validation_size: float = 0.1
    sequence_length: int = 50
    batch_size: int = 32
    epochs: int = 100
    early_stopping_patience: int = 10
    min_samples: int = 10000
    feature_importance_threshold: float = 0.01
    class_balance_method: str = 'smote'  # 'smote', 'undersample', 'oversample'
    
    def __post_init__(self):
        if self.lookback_periods is None:
            self.lookback_periods = [20, 50, 100, 200]

class AdvancedTrainingSystem:
    """–ü—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è —Å–∏—Å—Ç–µ–º–∞ –æ–±—É—á–µ–Ω–∏—è AI –º–æ–¥–µ–ª–µ–π"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.training_config = TrainingConfig(
            symbol=config.get('symbol', 'EURUSD'),
            timeframe=config.get('timeframe', 'H1')
        )
        
        # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
        self.data_dir = Path('data/market_data')
        self.models_dir = Path('data/models')
        self.reports_dir = Path('data/reports')
        self.models_dir.mkdir(parents=True, exist_ok=True)
        self.reports_dir.mkdir(parents=True, exist_ok=True)
        
        # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç—ã
        self.feature_engineer = AdvancedFeatureEngineer()
        self.ensemble_model = AdvancedEnsembleModel()
        self.backtester = AdvancedBacktester()
        self.performance_analyzer = PerformanceAnalyzer()
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è
        self.training_results = {}
        self.model_performance = {}
        
    def load_market_data(self, symbol: str, timeframe: str) -> Optional[pd.DataFrame]:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–∏—Å–∫ —Ñ–∞–π–ª–∞ –¥–∞–Ω–Ω—ã—Ö
            symbol_dir = self.data_dir / symbol
            pattern = f"{symbol}_{timeframe}_*.csv"
            
            files = list(symbol_dir.glob(pattern))
            if not files:
                logger.error(f"‚ùå –§–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –¥–ª—è {symbol} {timeframe}")
                return None
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ —Å–∞–º–æ–≥–æ —Å–≤–µ–∂–µ–≥–æ —Ñ–∞–π–ª–∞
            latest_file = max(files, key=lambda x: x.stat().st_mtime)
            logger.info(f"üìä –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑: {latest_file}")
            
            df = pd.read_csv(latest_file, index_col=0, parse_dates=True)
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(df)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è {symbol} {timeframe}")
            
            return df
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def prepare_training_data(self, df: pd.DataFrame) -> Tuple[np.ndarray, np.ndarray, List[str]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        try:
            logger.info("üîß –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è...")
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            df_features = self.feature_engineer.create_technical_indicators(df.copy())
            df_features = self.feature_engineer.create_advanced_features(df_features)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ NaN –∑–Ω–∞—á–µ–Ω–∏–π
            df_features = df_features.dropna()
            
            if len(df_features) < self.training_config.min_samples:
                logger.warning(f"‚ö†Ô∏è –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö: {len(df_features)} < {self.training_config.min_samples}")
                return None, None, None
            
            # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            target = self._create_target_variable(df_features['close'])
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
            feature_columns = [col for col in df_features.columns 
                             if col not in ['symbol', 'timeframe', 'open', 'high', 'low', 'close', 'tick_volume', 'spread', 'real_volume']]
            
            features = df_features[feature_columns].values
            target = target[~np.isnan(features).any(axis=1)]
            features = features[~np.isnan(features).any(axis=1)]
            
            logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(features)} –æ–±—Ä–∞–∑—Ü–æ–≤ —Å {len(feature_columns)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
            
            return features, target, feature_columns
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None, None
    
    def _create_target_variable(self, prices: pd.Series) -> np.ndarray:
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        try:
            # –†–∞—Å—á–µ—Ç –±—É–¥—É—â–∏—Ö –¥–æ—Ö–æ–¥–Ω–æ—Å—Ç–µ–π
            future_returns = prices.shift(-1) / prices - 1
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ—Ä–æ–≥–æ–≤ –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
            threshold_buy = 0.001   # 0.1% —Ä–æ—Å—Ç
            threshold_sell = -0.001  # 0.1% –ø–∞–¥–µ–Ω–∏–µ
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤
            target = np.zeros(len(prices))
            target[future_returns > threshold_buy] = 1    # BUY
            target[future_returns < threshold_sell] = 2   # SELL
            # 0 = HOLD (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)
            
            # –£–¥–∞–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ (–Ω–µ—Ç –±—É–¥—É—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö)
            target = target[:-1]
            
            return target
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π: {e}")
            return np.zeros(len(prices) - 1)
    
    def balance_classes(self, features: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤"""
        try:
            from imblearn.over_sampling import SMOTE
            from imblearn.under_sampling import RandomUnderSampler
            from imblearn.over_sampling import RandomOverSampler
            
            method = self.training_config.class_balance_method
            
            if method == 'smote':
                smote = SMOTE(random_state=42)
                features_balanced, target_balanced = smote.fit_resample(features, target)
            elif method == 'undersample':
                rus = RandomUnderSampler(random_state=42)
                features_balanced, target_balanced = rus.fit_resample(features, target)
            elif method == 'oversample':
                ros = RandomOverSampler(random_state=42)
                features_balanced, target_balanced = ros.fit_resample(features, target)
            else:
                features_balanced, target_balanced = features, target
            
            logger.info(f"‚úÖ –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤: {method}")
            logger.info(f"üìä –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –∫–ª–∞—Å—Å–æ–≤: {np.bincount(target_balanced)}")
            
            return features_balanced, target_balanced
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤: {e}")
            return features, target
    
    def split_data(self, features: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """–†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏"""
        try:
            # –í—Ä–µ–º–µ–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ (TimeSeriesSplit)
            tscv = TimeSeriesSplit(n_splits=5)
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π —Å–ø–ª–∏—Ç –¥–ª—è —Ñ–∏–Ω–∞–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
            for train_idx, test_idx in tscv.split(features):
                X_train, X_test = features[train_idx], features[test_idx]
                y_train, y_test = target[train_idx], target[test_idx]
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏
            split_point = int(len(X_train) * (1 - self.training_config.validation_size))
            X_train_final = X_train[:split_point]
            y_train_final = y_train[:split_point]
            X_val = X_train[split_point:]
            y_val = y_train[split_point:]
            
            logger.info(f"üìä –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö:")
            logger.info(f"   –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train_final)}")
            logger.info(f"   –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_val)}")
            logger.info(f"   –¢–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_test)}")
            
            return X_train_final, X_val, X_test, y_test
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None, None, None, None
    
    def train_models(self, X_train: np.ndarray, X_val: np.ndarray, y_train: np.ndarray, y_val: np.ndarray) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            logger.info("üéì –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π...")
            
            training_results = {}
            
            # –û–±—É—á–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model_name, model in self.ensemble_model.models.items():
                logger.info(f"üîÑ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏: {model_name}")
                
                try:
                    if hasattr(model, 'fit'):
                        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏ (XGBoost, LightGBM, RandomForest)
                        model.fit(X_train, y_train)
                        
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        y_pred_train = model.predict(X_train)
                        y_pred_val = model.predict(X_val)
                        
                        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                        train_accuracy = np.mean(y_pred_train == y_train)
                        val_accuracy = np.mean(y_pred_val == y_val)
                        
                        training_results[model_name] = {
                            'model': model,
                            'train_accuracy': train_accuracy,
                            'val_accuracy': val_accuracy,
                            'predictions_train': y_pred_train,
                            'predictions_val': y_pred_val
                        }
                        
                        logger.info(f"‚úÖ {model_name}: Train Acc={train_accuracy:.4f}, Val Acc={val_accuracy:.4f}")
                        
                    elif hasattr(model, 'create_model'):
                        # –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏ (LSTM, Transformer)
                        model_obj = model.create_model()
                        
                        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
                        X_train_seq, y_train_seq = self._prepare_sequences(X_train, y_train)
                        X_val_seq, y_val_seq = self._prepare_sequences(X_val, y_val)
                        
                        # –û–±—É—á–µ–Ω–∏–µ
                        history = model_obj.fit(
                            X_train_seq, y_train_seq,
                            validation_data=(X_val_seq, y_val_seq),
                            epochs=self.training_config.epochs,
                            batch_size=self.training_config.batch_size,
                            verbose=0
                        )
                        
                        # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                        y_pred_train = model_obj.predict(X_train_seq)
                        y_pred_val = model_obj.predict(X_val_seq)
                        
                        # –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞
                        train_accuracy = np.mean(np.argmax(y_pred_train, axis=1) == y_train)
                        val_accuracy = np.mean(np.argmax(y_pred_val, axis=1) == y_val)
                        
                        training_results[model_name] = {
                            'model': model_obj,
                            'history': history,
                            'train_accuracy': train_accuracy,
                            'val_accuracy': val_accuracy,
                            'predictions_train': y_pred_train,
                            'predictions_val': y_pred_val
                        }
                        
                        logger.info(f"‚úÖ {model_name}: Train Acc={train_accuracy:.4f}, Val Acc={val_accuracy:.4f}")
                        
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {model_name}: {e}")
                    continue
            
            self.training_results = training_results
            return training_results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
            return {}
    
    def _prepare_sequences(self, features: np.ndarray, target: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π –¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π"""
        try:
            sequence_length = self.training_config.sequence_length
            
            X_sequences = []
            y_sequences = []
            
            for i in range(sequence_length, len(features)):
                X_sequences.append(features[i-sequence_length:i])
                y_sequences.append(target[i])
            
            X_sequences = np.array(X_sequences)
            y_sequences = np.array(y_sequences)
            
            # One-hot encoding –¥–ª—è —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
            from sklearn.preprocessing import LabelEncoder
            le = LabelEncoder()
            y_encoded = le.fit_transform(y_sequences)
            
            from tensorflow.keras.utils import to_categorical
            y_categorical = to_categorical(y_encoded, num_classes=3)
            
            return X_sequences, y_categorical
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–µ–π: {e}")
            return np.array([]), np.array([])
    
    def evaluate_models(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict:
        """–û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π"""
        try:
            logger.info("üìä –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –º–æ–¥–µ–ª–µ–π...")
            
            evaluation_results = {}
            
            for model_name, result in self.training_results.items():
                model = result['model']
                
                try:
                    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ
                    if hasattr(model, 'predict'):
                        y_pred_test = model.predict(X_test)
                    else:
                        # –î–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π
                        X_test_seq, _ = self._prepare_sequences(X_test, y_test)
                        y_pred_test = model.predict(X_test_seq)
                        y_pred_test = np.argmax(y_pred_test, axis=1)
                    
                    # –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
                    accuracy = np.mean(y_pred_test == y_test)
                    
                    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
                    from sklearn.metrics import classification_report, confusion_matrix
                    class_report = classification_report(y_test, y_pred_test, output_dict=True)
                    conf_matrix = confusion_matrix(y_test, y_pred_test)
                    
                    evaluation_results[model_name] = {
                        'accuracy': accuracy,
                        'classification_report': class_report,
                        'confusion_matrix': conf_matrix,
                        'predictions': y_pred_test
                    }
                    
                    logger.info(f"üìä {model_name}: Test Accuracy = {accuracy:.4f}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ {model_name}: {e}")
                    continue
            
            self.model_performance = evaluation_results
            return evaluation_results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ—Ü–µ–Ω–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
            return {}
    
    def save_models(self, symbol: str, timeframe: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        try:
            logger.info("üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π...")
            
            model_dir = self.models_dir / symbol / timeframe
            model_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏
            for model_name, result in self.training_results.items():
                model = result['model']
                
                try:
                    if hasattr(model, 'save'):
                        # –ù–µ–π—Ä–æ–Ω–Ω—ã–µ —Å–µ—Ç–∏
                        model_path = model_dir / f"{model_name}.h5"
                        model.save(str(model_path))
                    else:
                        # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –º–æ–¥–µ–ª–∏
                        model_path = model_dir / f"{model_name}.pkl"
                        with open(model_path, 'wb') as f:
                            pickle.dump(model, f)
                    
                    logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –º–æ–¥–µ–ª—å: {model_path}")
                    
                except Exception as e:
                    logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è {model_name}: {e}")
                    continue
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
            metadata = {
                'symbol': symbol,
                'timeframe': timeframe,
                'training_date': datetime.now().isoformat(),
                'training_config': self.training_config.__dict__,
                'model_performance': self.model_performance,
                'feature_columns': getattr(self.feature_engineer, 'feature_names', [])
            }
            
            metadata_path = model_dir / 'training_metadata.json'
            with open(metadata_path, 'w') as f:
                json.dump(metadata, f, indent=2)
            
            logger.info(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {metadata_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π: {e}")
    
    def generate_training_report(self, symbol: str, timeframe: str):
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏"""
        try:
            logger.info("üìä –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞ –æ–± –æ–±—É—á–µ–Ω–∏–∏...")
            
            report_dir = self.reports_dir / symbol / timeframe
            report_dir.mkdir(parents=True, exist_ok=True)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report = {
                'training_info': {
                    'symbol': symbol,
                    'timeframe': timeframe,
                    'training_date': datetime.now().isoformat(),
                    'config': self.training_config.__dict__
                },
                'model_performance': self.model_performance,
                'training_results': {
                    name: {
                        'train_accuracy': result['train_accuracy'],
                        'val_accuracy': result['val_accuracy']
                    }
                    for name, result in self.training_results.items()
                }
            }
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á–µ—Ç–∞
            report_path = report_dir / 'training_report.json'
            with open(report_path, 'w') as f:
                json.dump(report, f, indent=2)
            
            # –°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π
            self._create_training_visualizations(report_dir)
            
            logger.info(f"üìä –û—Ç—á–µ—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω: {report_path}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç—á–µ—Ç–∞: {e}")
    
    def _create_training_visualizations(self, report_dir: Path):
        """–°–æ–∑–¥–∞–Ω–∏–µ –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π –¥–ª—è –æ—Ç—á–µ—Ç–∞"""
        try:
            # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π
            model_names = list(self.model_performance.keys())
            accuracies = [self.model_performance[name]['accuracy'] for name in model_names]
            
            plt.figure(figsize=(12, 8))
            
            # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏
            plt.subplot(2, 2, 1)
            plt.bar(model_names, accuracies)
            plt.title('–¢–æ—á–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–µ–π –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ')
            plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
            plt.xticks(rotation=45)
            
            # –ì—Ä–∞—Ñ–∏–∫ –æ–±—É—á–µ–Ω–∏—è (–¥–ª—è –Ω–µ–π—Ä–æ–Ω–Ω—ã—Ö —Å–µ—Ç–µ–π)
            plt.subplot(2, 2, 2)
            for model_name, result in self.training_results.items():
                if 'history' in result:
                    history = result['history']
                    plt.plot(history.history['accuracy'], label=f'{model_name} (train)')
                    plt.plot(history.history['val_accuracy'], label=f'{model_name} (val)')
            
            plt.title('–ö—Ä–∏–≤—ã–µ –æ–±—É—á–µ–Ω–∏—è')
            plt.xlabel('–≠–ø–æ—Ö–∞')
            plt.ylabel('–¢–æ—á–Ω–æ—Å—Ç—å')
            plt.legend()
            
            # –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
            for i, model_name in enumerate(model_names[:2]):
                plt.subplot(2, 2, 3 + i)
                conf_matrix = self.model_performance[model_name]['confusion_matrix']
                sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')
                plt.title(f'–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: {model_name}')
                plt.ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
                plt.xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è')
            
            plt.tight_layout()
            plt.savefig(report_dir / 'training_visualizations.png', dpi=300, bbox_inches='tight')
            plt.close()
            
            logger.info(f"üìä –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: {report_dir / 'training_visualizations.png'}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ–∑–¥–∞–Ω–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–π: {e}")
    
    def run_complete_training(self, symbol: str, timeframe: str) -> bool:
        """–ü–æ–ª–Ω—ã–π —Ü–∏–∫–ª –æ–±—É—á–µ–Ω–∏—è"""
        try:
            logger.info(f"üöÄ –ù–∞—á–∞–ª–æ –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è –¥–ª—è {symbol} {timeframe}")
            
            # –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df = self.load_market_data(symbol, timeframe)
            if df is None:
                return False
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            features, target, feature_columns = self.prepare_training_data(df)
            if features is None:
                return False
            
            # –ë–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∞ –∫–ª–∞—Å—Å–æ–≤
            features_balanced, target_balanced = self.balance_classes(features, target)
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
            X_train, X_val, X_test, y_test = self.split_data(features_balanced, target_balanced)
            if X_train is None:
                return False
            
            # –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            training_results = self.train_models(X_train, X_val, y_train, y_val)
            if not training_results:
                return False
            
            # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–µ–π
            evaluation_results = self.evaluate_models(X_test, y_test)
            if not evaluation_results:
                return False
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π
            self.save_models(symbol, timeframe)
            
            # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á–µ—Ç–∞
            self.generate_training_report(symbol, timeframe)
            
            logger.info("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ!")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è: {e}")
            return False

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è"""
    
    # –ó–∞–≥—Ä—É–∑–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏
    with open('config.json', 'r') as f:
        config = json.load(f)
    
    # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã –æ–±—É—á–µ–Ω–∏—è
    training_system = AdvancedTrainingSystem(config)
    
    # –û–±—É—á–µ–Ω–∏–µ –¥–ª—è –≤—Å–µ—Ö —Å–∏–º–≤–æ–ª–æ–≤ –∏ —Ç–∞–π–º—Ñ—Ä–µ–π–º–æ–≤
    symbols = config.get('mt5', {}).get('symbols', ['EURUSD'])
    timeframes = config.get('ai', {}).get('timeframes', ['H1'])
    
    for symbol in symbols:
        for timeframe in timeframes:
            logger.info(f"üéì –û–±—É—á–µ–Ω–∏–µ –¥–ª—è {symbol} {timeframe}")
            
            success = training_system.run_complete_training(symbol, timeframe)
            
            if success:
                logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ {symbol} {timeframe} –∑–∞–≤–µ—Ä—à–µ–Ω–æ —É—Å–ø–µ—à–Ω–æ")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {symbol} {timeframe}")

if __name__ == "__main__":
    main()