#!/usr/bin/env python3
"""
Single Pair Model System
–°–∏—Å—Ç–µ–º–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è –æ–¥–Ω–æ–π –≤–∞–ª—é—Ç–Ω–æ–π –ø–∞—Ä—ã
"""

import numpy as np
import pandas as pd
import joblib
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from pathlib import Path
import logging
from sklearn.model_selection import TimeSeriesSplit
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
import xgboost as xgb
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier

from advanced_ai_models import (
    AdvancedFeatureEngineer,
    AdvancedLSTMModel,
    AdvancedTransformerModel,
    AdvancedEnsembleModel,
    create_advanced_models
)
from advanced_backtesting import AdvancedBacktester

logger = logging.getLogger(__name__)

class SinglePairModel:
    """–ú–æ–¥–µ–ª—å –¥–ª—è –æ–¥–Ω–æ–π –≤–∞–ª—é—Ç–Ω–æ–π –ø–∞—Ä—ã"""
    
    def __init__(self, symbol: str, timeframe: str, config: Dict):
        self.symbol = symbol
        self.timeframe = timeframe
        self.config = config
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è –º–æ–¥–µ–ª–∏
        self.model_dir = Path(f"data/models/{symbol}/{timeframe}")
        self.model_dir.mkdir(parents=True, exist_ok=True)
        
        # –ò–Ω–∂–µ–Ω–µ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.feature_engineer = AdvancedFeatureEngineer()
        
        # –ê–Ω—Å–∞–º–±–ª—å –º–æ–¥–µ–ª–µ–π
        self.ensemble_model = create_advanced_models()
        
        # Backtester
        self.backtester = AdvancedBacktester()
        
        # –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–∏
        self.model_status = {
            "symbol": symbol,
            "timeframe": timeframe,
            "trained": False,
            "last_trained": None,
            "accuracy": 0.0,
            "backtest_results": {},
            "model_info": {}
        }
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏
        self._load_existing_model()
    
    def _load_existing_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–µ–π –º–æ–¥–µ–ª–∏"""
        try:
            model_files = list(self.model_dir.glob("*.joblib"))
            if model_files:
                latest_file = max(model_files, key=lambda x: x.stat().st_mtime)
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
                self.ensemble_model = joblib.load(latest_file)
                
                # –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                metadata_path = latest_file.with_suffix('_metadata.json')
                if metadata_path.exists():
                    with open(metadata_path, 'r') as f:
                        metadata = json.load(f)
                    
                    self.model_status.update({
                        "trained": True,
                        "last_trained": metadata.get('training_date'),
                        "accuracy": metadata.get('training_metrics', {}).get('accuracy', 0.0),
                        "model_info": metadata
                    })
                
                logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—É—â–µ—Å—Ç–≤—É—é—â–∞—è –º–æ–¥–µ–ª—å –¥–ª—è {self.symbol} {self.timeframe}")
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å: {e}")
    
    def prepare_data(self, start_date: str, end_date: str) -> Tuple[pd.DataFrame, np.ndarray, List[str]]:
        """–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è"""
        
        logger.info(f"üìä –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} {self.timeframe}")
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        df = self._load_market_data(start_date, end_date)
        
        if df.empty:
            raise ValueError(f"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {self.symbol} {self.timeframe}")
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
        df = self.feature_engineer.create_technical_indicators(df)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        df = self.feature_engineer.create_advanced_features(df)
        
        # –£–¥–∞–ª–µ–Ω–∏–µ NaN –∑–Ω–∞—á–µ–Ω–∏–π
        df = df.dropna()
        
        # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        features, feature_names = self.feature_engineer.prepare_features(df)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π
        target = self.ensemble_model._create_target_variable(df['close'])
        
        logger.info(f"‚úÖ –ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(features)} –∑–∞–ø–∏—Å–µ–π —Å {len(feature_names)} –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏")
        
        return df, features, target, feature_names
    
    def _load_market_data(self, start_date: str, end_date: str) -> pd.DataFrame:
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—ã"""
        
        start_dt = datetime.strptime(start_date, '%Y-%m-%d')
        end_dt = datetime.strptime(end_date, '%Y-%m-%d')
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —á–∞—Å—Ç–æ—Ç—ã –¥–∞–Ω–Ω—ã—Ö
        if self.timeframe == 'M15':
            freq = '15T'
        elif self.timeframe == 'H1':
            freq = 'H'
        elif self.timeframe == 'H4':
            freq = '4H'
        elif self.timeframe == 'D1':
            freq = 'D'
        else:
            freq = 'H'
        
        dates = pd.date_range(start_dt, end_dt, freq=freq)
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö (–∑–∞–º–µ–Ω–∏—Ç–µ –Ω–∞ —Ä–µ–∞–ª—å–Ω—É—é –∑–∞–≥—Ä—É–∑–∫—É)
        np.random.seed(42)
        
        # –ë–∞–∑–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–∞—Ä—ã
        if self.symbol == 'EURUSD':
            base_price = 1.0850
            volatility = 0.001
        elif self.symbol == 'GBPUSD':
            base_price = 1.2650
            volatility = 0.0015
        elif self.symbol == 'USDJPY':
            base_price = 150.0
            volatility = 0.5
        else:
            base_price = 1.0
            volatility = 0.001
        
        # –°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–Ω—ã —Å —É—á–µ—Ç–æ–º —Å–ø–µ—Ü–∏—Ñ–∏–∫–∏ –ø–∞—Ä—ã
        price = base_price + np.cumsum(np.random.randn(len(dates)) * volatility)
        volume = np.random.randint(1000, 10000, len(dates))
        
        df = pd.DataFrame({
            'open': price * (1 + np.random.randn(len(dates)) * 0.0005),
            'high': price * (1 + abs(np.random.randn(len(dates)) * 0.001)),
            'low': price * (1 - abs(np.random.randn(len(dates)) * 0.001)),
            'close': price,
            'volume': volume
        }, index=dates)
        
        return df
    
    def train_model(self, start_date: str, end_date: str, validation_split: float = 0.2) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –ø–∞—Ä—ã"""
        
        logger.info(f"üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è {self.symbol} {self.timeframe}")
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df, features, target, feature_names = self.prepare_data(start_date, end_date)
            
            # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ –æ–±—É—á–∞—é—â—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏
            split_idx = int(len(features) * (1 - validation_split))
            
            X_train = features[:split_idx]
            y_train = target[:split_idx]
            X_val = features[split_idx:]
            y_val = target[split_idx:]
            
            logger.info(f"üìà –û–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_train)} –∑–∞–ø–∏—Å–µ–π")
            logger.info(f"üìä –í–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞: {len(X_val)} –∑–∞–ø–∏—Å–µ–π")
            
            # –û–±—É—á–µ–Ω–∏–µ –∞–Ω—Å–∞–º–±–ª—è –º–æ–¥–µ–ª–µ–π
            training_results = self.ensemble_model.train_models(df.iloc[:split_idx])
            
            # –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π
            validation_results = self._validate_models(X_val, y_val)
            
            # Backtesting –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            backtest_results = self._backtest_validation(df.iloc[split_idx:], X_val, y_val)
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
            model_info = self._save_model(training_results, feature_names)
            
            # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            self.model_status.update({
                "trained": True,
                "last_trained": datetime.now().isoformat(),
                "accuracy": validation_results.get('ensemble_accuracy', 0.0),
                "backtest_results": backtest_results,
                "model_info": model_info
            })
            
            # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
            self._save_model_status()
            
            logger.info(f"‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {self.symbol} {self.timeframe}")
            
            return {
                'training_results': training_results,
                'validation_results': validation_results,
                'backtest_results': backtest_results,
                'model_info': model_info
            }
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ {self.symbol} {self.timeframe}: {e}")
            return {'error': str(e)}
    
    def _validate_models(self, X_val: np.ndarray, y_val: np.ndarray) -> Dict:
        """–í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π"""
        validation_results = {}
        
        for model_name, model in self.ensemble_model.models.items():
            try:
                if hasattr(model, 'predict'):
                    predictions = model.predict(X_val)
                    
                    # –†–∞—Å—á–µ—Ç —Ç–æ—á–Ω–æ—Å—Ç–∏
                    if len(predictions.shape) > 1:
                        y_pred = np.argmax(predictions, axis=1)
                    else:
                        y_pred = predictions
                    
                    accuracy = np.mean(y_pred == y_val)
                    validation_results[model_name] = {
                        'accuracy': accuracy,
                        'predictions_shape': predictions.shape
                    }
                    
                    logger.info(f"üìä {model_name}: —Ç–æ—á–Ω–æ—Å—Ç—å = {accuracy:.4f}")
                    
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏ {model_name}: {e}")
                validation_results[model_name] = {'error': str(e)}
        
        # –†–∞—Å—á–µ—Ç —Å—Ä–µ–¥–Ω–µ–π —Ç–æ—á–Ω–æ—Å—Ç–∏ –∞–Ω—Å–∞–º–±–ª—è
        accuracies = [result.get('accuracy', 0) for result in validation_results.values() if 'accuracy' in result]
        if accuracies:
            validation_results['ensemble_accuracy'] = sum(accuracies) / len(accuracies)
        
        return validation_results
    
    def _backtest_validation(self, df_val: pd.DataFrame, X_val: np.ndarray, y_val: np.ndarray) -> Dict:
        """Backtesting –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –∞–Ω—Å–∞–º–±–ª—è
            ensemble_predictions = self.ensemble_model.predict_ensemble(df_val)
            predictions = ensemble_predictions['ensemble_prediction']
            
            # –ó–∞–ø—É—Å–∫ backtesting
            backtest_results = self.backtester.run_backtest(
                df_val, predictions, confidence_threshold=0.6
            )
            
            logger.info(f"üìà Backtesting —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è {self.symbol} {self.timeframe}:")
            logger.info(f"   –û–±—â–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–¥–µ–ª–æ–∫: {backtest_results['total_trades']}")
            logger.info(f"   –í–∏–Ω—Ä–µ–π—Ç: {backtest_results['win_rate']:.2f}%")
            logger.info(f"   –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {backtest_results['total_profit']:.2f}")
            logger.info(f"   Sharpe Ratio: {backtest_results['sharpe_ratio']:.4f}")
            
            return backtest_results
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ backtesting: {e}")
            return {'error': str(e)}
    
    def _save_model(self, training_results: Dict, feature_names: List[str]) -> Dict:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        model_path = self.model_dir / f"{self.symbol}_{self.timeframe}_{timestamp}.joblib"
        joblib.dump(self.ensemble_model, model_path)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
        metadata = {
            'symbol': self.symbol,
            'timeframe': self.timeframe,
            'training_date': datetime.now().isoformat(),
            'model_path': str(model_path),
            'training_metrics': training_results,
            'feature_names': feature_names,
            'feature_count': len(feature_names),
            'model_type': 'SinglePairEnsemble'
        }
        
        metadata_path = self.model_dir / f"{self.symbol}_{self.timeframe}_{timestamp}_metadata.json"
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
        feature_info_path = self.model_dir / "feature_info.json"
        with open(feature_info_path, 'w') as f:
            json.dump({'feature_names': feature_names}, f, indent=2)
        
        logger.info(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {model_path}")
        
        return {
            'model_path': str(model_path),
            'metadata_path': str(metadata_path),
            'feature_count': len(feature_names)
        }
    
    def _save_model_status(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –º–æ–¥–µ–ª–∏"""
        status_path = self.model_dir / "model_status.json"
        with open(status_path, 'w') as f:
            json.dump(self.model_status, f, indent=2)
    
    def predict(self, market_data: pd.DataFrame) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
        
        if not self.model_status['trained']:
            return {'error': 'Model not trained'}
        
        try:
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö
            df = self.feature_engineer.create_technical_indicators(market_data)
            df = self.feature_engineer.create_advanced_features(df)
            df = df.dropna()
            
            if df.empty:
                return {'error': 'No valid data after preprocessing'}
            
            # –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
            prediction = self.ensemble_model.predict_ensemble(df)
            
            # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏
            prediction['model_info'] = {
                'symbol': self.symbol,
                'timeframe': self.timeframe,
                'last_trained': self.model_status['last_trained'],
                'accuracy': self.model_status['accuracy']
            }
            
            return prediction
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return {'error': str(e)}
    
    def get_model_info(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –º–æ–¥–µ–ª–∏"""
        return self.model_status
    
    def retrain_model(self, days_back: int = 365) -> Dict:
        """–ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        
        logger.info(f"üîÑ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {self.symbol} {self.timeframe}")
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞ –æ–±—É—á–µ–Ω–∏—è
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days_back)
        
        # –û–±—É—á–µ–Ω–∏–µ –Ω–∞ –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        results = self.train_model(
            start_date.strftime('%Y-%m-%d'),
            end_date.strftime('%Y-%m-%d')
        )
        
        logger.info(f"‚úÖ –ü–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ –¥–ª—è {self.symbol} {self.timeframe}")
        
        return results

class SinglePairModelManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–∞—Ä"""
    
    def __init__(self, config: Dict):
        self.config = config
        self.models = {}
        self.models_dir = Path("data/models")
        
    def create_model(self, symbol: str, timeframe: str) -> SinglePairModel:
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è –ø–∞—Ä—ã"""
        
        model_key = f"{symbol}_{timeframe}"
        
        if model_key not in self.models:
            self.models[model_key] = SinglePairModel(symbol, timeframe, self.config)
            logger.info(f"‚úÖ –°–æ–∑–¥–∞–Ω–∞ –º–æ–¥–µ–ª—å –¥–ª—è {symbol} {timeframe}")
        
        return self.models[model_key]
    
    def train_all_models(self, pairs: List[Tuple[str, str]], 
                        start_date: str, end_date: str) -> Dict:
        """–û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        
        results = {}
        
        for symbol, timeframe in pairs:
            logger.info(f"üéØ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ {symbol} {timeframe}")
            
            model = self.create_model(symbol, timeframe)
            result = model.train_model(start_date, end_date)
            
            results[f"{symbol}_{timeframe}"] = result
            
            if 'error' not in result:
                logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å {symbol} {timeframe} –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            else:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è {symbol} {timeframe}: {result['error']}")
        
        return results
    
    def get_model_status(self) -> Dict:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        status = {}
        
        for model_key, model in self.models.items():
            status[model_key] = model.get_model_info()
        
        return status
    
    def predict_all(self, market_data: Dict) -> Dict:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        predictions = {}
        
        for model_key, model in self.models.items():
            if model_key in market_data:
                prediction = model.predict(market_data[model_key])
                predictions[model_key] = prediction
        
        return predictions

# –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    config = {
        "ai": {
            "models": ["lstm", "xgboost", "lightgbm"],
            "timeframes": ["H1", "H4"],
            "min_accuracy_threshold": 0.65
        }
    }
    
    # –°–æ–∑–¥–∞–Ω–∏–µ –º–µ–Ω–µ–¥–∂–µ—Ä–∞
    manager = SinglePairModelManager(config)
    
    # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–∞—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    pairs = [
        ("EURUSD", "H1"),
        ("GBPUSD", "H1"),
        ("USDJPY", "H1"),
        ("EURUSD", "H4"),
        ("GBPUSD", "H4")
    ]
    
    # –û–±—É—á–µ–Ω–∏–µ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
    print("üöÄ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö –ø–∞—Ä...")
    
    results = manager.train_all_models(
        pairs=pairs,
        start_date="2023-01-01",
        end_date="2023-12-31"
    )
    
    # –ê–Ω–∞–ª–∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    print("\nüìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—É—á–µ–Ω–∏—è:")
    for pair_key, result in results.items():
        if 'error' not in result:
            validation = result.get('validation_results', {})
            backtest = result.get('backtest_results', {})
            
            print(f"\n{pair_key}:")
            print(f"  –¢–æ—á–Ω–æ—Å—Ç—å: {validation.get('ensemble_accuracy', 0):.4f}")
            print(f"  –°–¥–µ–ª–∫–∏: {backtest.get('total_trades', 0)}")
            print(f"  –í–∏–Ω—Ä–µ–π—Ç: {backtest.get('win_rate', 0):.2f}%")
            print(f"  –ü—Ä–∏–±—ã–ª—å: {backtest.get('total_profit', 0):.2f}")
        else:
            print(f"\n{pair_key}: –û—à–∏–±–∫–∞ - {result['error']}")
    
    # –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞
    status = manager.get_model_status()
    print(f"\nüìã –°—Ç–∞—Ç—É—Å –º–æ–¥–µ–ª–µ–π:")
    for pair_key, info in status.items():
        print(f"  {pair_key}: {'–û–±—É—á–µ–Ω–∞' if info['trained'] else '–ù–µ –æ–±—É—á–µ–Ω–∞'}")
    
    print("\nüéâ –û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")